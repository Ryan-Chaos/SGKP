{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "source": [
    "import matplotlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "import torch\n",
    "\n",
    "from scipy.io import loadmat\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "source": [
    "%matplotlib inline"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device('cuda:0' if use_cuda else 'cpu')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "source": [
    "# Add new methods here.\n",
    "# methods = ['ORB', 'ORB+Boost-B', 'SIFT', 'SIFT+Boost-F', 'SIFT+Boost-B', 'RootSIFT', 'SOSNet', 'SuperPoint', 'SuperPoint+Boost-F', 'SuperPoint+Boost-B', 'ALIKE', 'ALIKE+Boost-F', 'ALIKE+Boost-B']\n",
    "methods = ['SuperPoint', 'SuperPoint+Boost-F', 'SuperPoint+Boost-B']\n",
    "# names = ['ORB', 'ORB+Boost-B', 'SIFT', 'SIFT+Boost-F', 'SIFT+Boost-B', 'RootSIFT', 'SOSNet', 'SuperPoint', 'SuperPoint+Boost-F', 'SuperPoint+Boost-B', 'ALIKE', 'ALIKE+Boost-F', 'ALIKE+Boost-B']\n",
    "names = ['SuperPoint', 'SuperPoint+Boost-F', 'SuperPoint+Boost-B']\n",
    "# colors = ['orange', 'orange', 'green', 'green', 'green', 'blue', 'cyan', 'red', 'red', 'red', 'purple', 'purple', 'purple']\n",
    "# linestyles = ['-', '--', '-', '--', '-.', '-', '-', '-', '--', '-.', '-', '--', '-.']\n",
    "colors = ['red', 'red', 'red']\n",
    "linestyles = ['-', '--', '-.']"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "source": [
    "n_i = 52\n",
    "n_v = 56"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T07:51:20.635571Z",
     "start_time": "2024-05-18T07:51:20.627565Z"
    }
   },
   "source": [
    "dataset_path = 'hpatches-sequences-release'\n",
    "# TODO 数据集路径要改"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "source": [
    "lim = [1, 15]\n",
    "rng = np.arange(lim[0], lim[1] + 1)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "source": [
    "def mnn_matcher(descriptors_a, descriptors_b):\n",
    "    device = descriptors_a.device\n",
    "    sim = descriptors_a @ descriptors_b.t()\n",
    "    nn12 = torch.max(sim, dim=1)[1]\n",
    "    nn21 = torch.max(sim, dim=0)[1]\n",
    "    ids1 = torch.arange(0, sim.shape[0], device=device)\n",
    "    mask = (ids1 == nn21[nn12])\n",
    "    matches = torch.stack([ids1[mask], nn12[mask]])\n",
    "    return matches.t().data.cpu().numpy()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# 这里是评估的主要函数\n",
    "def benchmark_features(read_feats):\n",
    "    seq_names = sorted(os.listdir(dataset_path)) # ：这行代码列出了dataset_path目录中的所有文件和文件夹，并将它们排序\n",
    "\n",
    "    # 初始化了几个列表和字典来存储特征点数量、匹配数量、序列类型以及不同阈值下的错误率和匹配数\n",
    "    n_feats = []\n",
    "    n_matches = []\n",
    "    seq_type = []\n",
    "    i_err = {thr: 0 for thr in rng}\n",
    "    i_matches = {thr: 0 for thr in rng}\n",
    "    v_err = {thr: 0 for thr in rng}\n",
    "    v_matches = {thr: 0 for thr in rng}\n",
    "\n",
    "    for seq_idx, seq_name in tqdm(enumerate(seq_names), total=len(seq_names)):\n",
    "        keypoints_a, descriptors_a = read_feats(seq_name, 1) # 对于每个序列，读取第一幅图像的关键点和描述符\n",
    "        n_feats.append(keypoints_a.shape[0])\n",
    "\n",
    "        for im_idx in range(2, 7): # 内部循环，对于每个序列，读取第2到第6幅图像的关键点和描述符\n",
    "            keypoints_b, descriptors_b = read_feats(seq_name, im_idx)\n",
    "            n_feats.append(keypoints_b.shape[0])\n",
    "\n",
    "            matches = mnn_matcher( # 使用最近邻匹配器找到描述符之间的匹配\n",
    "                torch.from_numpy(descriptors_a).to(device=device), \n",
    "                torch.from_numpy(descriptors_b).to(device=device)\n",
    "            )\n",
    "            \n",
    "            homography = np.loadtxt(os.path.join(dataset_path, seq_name, \"H_1_\" + str(im_idx))) # 加载两幅图像之间的单应性矩阵\n",
    "            \n",
    "            # 计算匹配点之间的位置误差\n",
    "            pos_a = keypoints_a[matches[:, 0], : 2]  # 从关键点数组keypoints_a中提取出所有匹配的第一组关键点的位置信息\n",
    "            pos_a_h = np.concatenate([pos_a, np.ones([matches.shape[0], 1])], axis=1) # 这里将pos_a的每个点扩展为齐次坐标形式，即在每个点的x和y坐标后面添加了一个1\n",
    "            pos_b_proj_h = np.transpose(np.dot(homography, np.transpose(pos_a_h))) # 通过单应性矩阵homography将pos_a_h中的点投影到第二幅图像的坐标系中\n",
    "            pos_b_proj = pos_b_proj_h[:, : 2] / pos_b_proj_h[:, 2 :] # 将投影点的齐次坐标转换回普通坐标\n",
    "\n",
    "            pos_b = keypoints_b[matches[:, 1], : 2] # 从关键点数组keypoints_b中提取出所有匹配的第二组关键点的位置信息\n",
    "\n",
    "            dist = np.sqrt(np.sum((pos_b - pos_b_proj) ** 2, axis=1)) # 计算每对匹配点之间的欧氏距离，这是通过取实际点pos_b和投影点pos_b_proj之间差的平方和的平方根来实现的\n",
    "\n",
    "            n_matches.append(matches.shape[0]) # 将当前匹配的数量添加到n_matches列表中\n",
    "            seq_type.append(seq_name[0]) # 将当前序列的类型（例如，如果序列名称以'i'开头，则为内部序列）添加到seq_type列表中\n",
    "            \n",
    "            if dist.shape[0] == 0:\n",
    "                dist = np.array([float(\"inf\")])\n",
    "            \n",
    "            for thr in rng: # 计算不同阈值下的平均误差和匹配数\n",
    "                if seq_name[0] == 'i':\n",
    "                    i_err[thr] += np.mean(dist <= thr)\n",
    "                    i_matches[thr] += np.sum(dist <= thr)\n",
    "                else:\n",
    "                    v_err[thr] += np.mean(dist <= thr)\n",
    "                    v_matches[thr] += np.sum(dist <= thr)\n",
    "    \n",
    "    seq_type = np.array(seq_type)\n",
    "    n_feats = np.array(n_feats)\n",
    "    n_matches = np.array(n_matches)\n",
    "    \n",
    "    return i_err, v_err, i_matches, v_matches, [seq_type, n_feats, n_matches]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "source": [
    "def summary(stats):\n",
    "    seq_type, n_feats, n_matches = stats\n",
    "    print('# Features: {:f} - [{:d}, {:d}]'.format(np.mean(n_feats), np.min(n_feats), np.max(n_feats)))\n",
    "    print('# Matches: Overall {:f}, Illumination {:f}, Viewpoint {:f}'.format(\n",
    "        np.sum(n_matches) / ((n_i + n_v) * 5), \n",
    "        np.sum(n_matches[seq_type == 'i']) / (n_i * 5), \n",
    "        np.sum(n_matches[seq_type == 'v']) / (n_v * 5))\n",
    "    )"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "source": [
    "def getBit(des):\n",
    "    res = []\n",
    "    for d in des:\n",
    "        for i in range(8):\n",
    "            res.append(((d >> i) & 1) * 2 - 1)\n",
    "    return res\n",
    "\n",
    "def generate_read_function(method, extension='ppm', type='float'): # 创建读取图像数据的函数\n",
    "    def read_function(seq_name, im_idx):\n",
    "        aux = np.load(os.path.join(dataset_path, seq_name, '%d.%s.%s' % (im_idx, extension, method))) # 从文件中加载数据\n",
    "        if type == 'float': # 如果参数 type 为 'float'，则函数返回从加载的数据中得到的 'keypoints' 和 'descriptors'\n",
    "            return aux['keypoints'], aux['descriptors']\n",
    "        else: # 处理 'descriptors' 数据，通过解包其位并缩放值\n",
    "            descriptors = np.unpackbits(aux['descriptors'], axis=1, bitorder='little')\n",
    "            descriptors = descriptors * 2.0 - 1.0\n",
    "            return aux['keypoints'], descriptors\n",
    "    return read_function"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "source": [
    "def sift_to_rootsift(descriptors):\n",
    "    return np.sqrt(descriptors / np.expand_dims(np.sum(np.abs(descriptors), axis=1), axis=1) + 1e-16)\n",
    "def parse_mat(mat):\n",
    "    keypoints = mat['keypoints'][:, : 2]\n",
    "    raw_descriptors = mat['descriptors']\n",
    "    l2_norm_descriptors = raw_descriptors / np.expand_dims(np.sum(raw_descriptors ** 2, axis=1), axis=1)\n",
    "    descriptors = sift_to_rootsift(l2_norm_descriptors)\n",
    "    return keypoints, descriptors"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "source": [
    "cache_dir = 'cache'\n",
    "if not os.path.isdir(cache_dir):\n",
    "    os.mkdir(cache_dir)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "source": [
    "errors = {}"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "source": [
    "for method in methods:\n",
    "    output_file = os.path.join(cache_dir, method + '.npy')\n",
    "    print(method)\n",
    "    if method == 'hesaff':\n",
    "        read_function = lambda seq_name, im_idx: parse_mat(loadmat(os.path.join(dataset_path, seq_name, '%d.ppm.hesaff' % im_idx), appendmat=False))\n",
    "    else:\n",
    "        if method == 'delf' or method == 'delf-new':\n",
    "            read_function = generate_read_function(method, extension='png')\n",
    "        elif '+Boost-B' in method or (method.lower() == 'orb'):\n",
    "            read_function = generate_read_function(method, type='binary')\n",
    "        else:\n",
    "            read_function = generate_read_function(method)  # 创建读取图像数据的函数read_function\n",
    "    if os.path.exists(output_file):\n",
    "        print('Loading precomputed errors...')\n",
    "        errors[method] = np.load(output_file, allow_pickle=True)# 如果文件存在，使用 np.load 加载文件数据到 errors字典中xxxx\n",
    "    else: # 主要在这里\n",
    "        errors[method] = benchmark_features(read_function) # 如果不存在，调用 benchmark_features 函数对特征进行评估，并将结果存储在 errors 字典中\n",
    "        np.save(output_file, errors[method])\n",
    "    summary(errors[method][-1]) # 调用 summary 函数，传入 errors 字典中当前方法的最后一个元素，以生成和打印性能摘要"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "source": [
    "for method in methods:\n",
    "    i_err, v_err, i_matches, v_matches, _ = errors[method]\n",
    "    # 从 errors 字典中提取当前方法的错误和匹配信息，i_err 和 v_err 分别代表在不同阈值下的照明和视角错误，i_matches 和 v_matches 代表匹配的内点数\n",
    "    print(method)\n",
    "    for thr in [1, 3, 5]:\n",
    "        print('# MMA@{:d}: Overall {:f}, Illumination {:f}, Viewpoint {:f}'.format( # 这里计算了整体的MMA、照明条件下的MMA和视角变化下的MMA\n",
    "            thr,\n",
    "            (i_err[thr] + v_err[thr]) / ((n_i + n_v) * 5), \n",
    "            i_err[thr] / (n_i * 5), \n",
    "            v_err[thr] / (n_v * 5))\n",
    "        )\n",
    "        print('# inliers@{:d}: Overall {:f}, Illumination {:f}, Viewpoint {:f}'.format( # 这里计算了整体的内点数、照明条件下的内点数和视角变化下的内点数\n",
    "            thr,\n",
    "            (i_matches[thr] + v_matches[thr]) / ((n_i + n_v) * 5), \n",
    "            i_matches[thr] / (n_i * 5), \n",
    "            v_matches[thr] / (n_v * 5))\n",
    "        )"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "source": [
    "plt_lim = [1, 10]\n",
    "plt_rng = np.arange(plt_lim[0], plt_lim[1] + 1)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "source": [
    "plt.rc('axes', titlesize=25)\n",
    "plt.rc('axes', labelsize=25)\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "for method, name, color, ls in zip(methods, names, colors, linestyles):\n",
    "    i_err, v_err, _, _, _ = errors[method]\n",
    "    plt.plot(plt_rng, [(i_err[thr] + v_err[thr]) / ((n_i + n_v) * 5) for thr in plt_rng], color=color, ls=ls, linewidth=2, label=name)\n",
    "plt.title('Overall')\n",
    "plt.xlim(plt_lim)\n",
    "plt.xticks(plt_rng)\n",
    "plt.ylabel('MMA')\n",
    "plt.ylim([0, 1])\n",
    "plt.grid()\n",
    "plt.tick_params(axis='both', which='major', labelsize=20)\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "for method, name, color, ls in zip(methods, names, colors, linestyles):\n",
    "    i_err, v_err, _, _, _ = errors[method]\n",
    "    plt.plot(plt_rng, [i_err[thr] / (n_i * 5) for thr in plt_rng], color=color, ls=ls, linewidth=2, label=name)\n",
    "plt.title('Illumination')\n",
    "plt.xlabel('threshold [px]')\n",
    "plt.xlim(plt_lim)\n",
    "plt.xticks(plt_rng)\n",
    "plt.ylim([0, 1])\n",
    "plt.gca().axes.set_yticklabels([])\n",
    "plt.grid()\n",
    "plt.tick_params(axis='both', which='major', labelsize=20)\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "for method, name, color, ls in zip(methods, names, colors, linestyles):\n",
    "    i_err, v_err, _, _, _ = errors[method]\n",
    "    plt.plot(plt_rng, [v_err[thr] / (n_v * 5) for thr in plt_rng], color=color, ls=ls, linewidth=2, label=name)\n",
    "plt.title('Viewpoint')\n",
    "plt.xlim(plt_lim)\n",
    "plt.xticks(plt_rng)\n",
    "plt.ylim([0, 1])\n",
    "plt.gca().axes.set_yticklabels([])\n",
    "plt.grid()\n",
    "plt.tick_params(axis='both', which='major', labelsize=20)\n",
    "\n",
    "plt.savefig('hseq.pdf', bbox_inches='tight', dpi=300)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "source": [
    "plt.rc('axes', titlesize=25)\n",
    "plt.rc('axes', labelsize=25)\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "for method, name, color, ls in zip(methods, names, colors, linestyles):\n",
    "    _, _, i_matches, v_matches, _ = errors[method]\n",
    "    plt.plot(plt_rng, [(i_matches[thr] + v_matches[thr]) / ((n_i + n_v) * 5) for thr in plt_rng], color=color, ls=ls, linewidth=2, label=name)\n",
    "plt.title('Overall')\n",
    "plt.xlim(plt_lim)\n",
    "plt.xticks(plt_rng)\n",
    "plt.ylabel('Mean Inliners')\n",
    "plt.ylim([0, 1500])\n",
    "plt.grid()\n",
    "plt.tick_params(axis='both', which='major', labelsize=20)\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "for method, name, color, ls in zip(methods, names, colors, linestyles):\n",
    "    _, _, i_matches, v_matches, _ = errors[method]\n",
    "    plt.plot(plt_rng, [i_matches[thr] / (n_i * 5) for thr in plt_rng], color=color, ls=ls, linewidth=2, label=name)\n",
    "plt.title('Illumination')\n",
    "plt.xlabel('threshold [px]')\n",
    "plt.xlim(plt_lim)\n",
    "plt.xticks(plt_rng)\n",
    "plt.ylim([0, 1500])\n",
    "plt.gca().axes.set_yticklabels([])\n",
    "plt.grid()\n",
    "plt.tick_params(axis='both', which='major', labelsize=20)\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "for method, name, color, ls in zip(methods, names, colors, linestyles):\n",
    "    _, _, i_matches, v_matches, _ = errors[method]\n",
    "    plt.plot(plt_rng, [v_matches[thr] / (n_v * 5) for thr in plt_rng], color=color, ls=ls, linewidth=2, label=name)\n",
    "plt.title('Viewpoint')\n",
    "plt.xlim(plt_lim)\n",
    "plt.xticks(plt_rng)\n",
    "plt.ylim([0, 1500])\n",
    "plt.gca().axes.set_yticklabels([])\n",
    "plt.grid()\n",
    "plt.tick_params(axis='both', which='major', labelsize=20)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "24293eb685027aff9d7e9b62d4252b11fbd82aacc5f7e332be036278e88fb5d8"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('devFeatureCUDA11')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
